import { useState } from 'react';

interface Props { onNavigate: (page: string) => void; }

interface Term { term: string; def: string; category: string; }

const TERMS: Term[] = [
    { term: 'Inference', def: 'The process of generating output from a model given an input prompt. This is what happens when you send a request to the API.', category: 'Core' },
    { term: 'Token', def: 'The basic unit of text processing. Roughly 4 characters or ¬æ of a word in English. Both input and output are measured in tokens.', category: 'Core' },
    { term: 'Context Window', def: 'The maximum number of tokens a model can process in a single request, including both prompt and completion.', category: 'Core' },
    { term: 'Prompt', def: 'The input text sent to a model. Can include system instructions, user messages, and conversation history.', category: 'Core' },
    { term: 'Completion', def: 'The text generated by the model in response to a prompt. Also called the model\'s "output" or "response".', category: 'Core' },
    { term: 'Fine-Tuning', def: 'Training a pre-trained model on your specific dataset to improve performance on domain-specific tasks.', category: 'Training' },
    { term: 'LoRA', def: 'Low-Rank Adaptation. An efficient fine-tuning method that trains small adapter layers instead of modifying all model weights.', category: 'Training' },
    { term: 'QLoRA', def: 'Quantized LoRA. Combines 4-bit quantization with LoRA to reduce GPU memory requirements during fine-tuning.', category: 'Training' },
    { term: 'Embedding', def: 'A dense vector representation of text that captures semantic meaning. Used for search, clustering, and similarity.', category: 'Vectors' },
    { term: 'VRAM', def: 'Video RAM. GPU memory used to store model weights during inference. Larger models require more VRAM.', category: 'Hardware' },
    { term: 'Quantization', def: 'Reducing model precision (e.g., FP16‚ÜíINT4) to decrease memory usage and increase speed with minimal quality loss.', category: 'Hardware' },
    { term: 'Streaming', def: 'Receiving model output token-by-token as it\'s generated, rather than waiting for the full response.', category: 'API' },
    { term: 'Temperature', def: 'Controls randomness in generation. 0 = deterministic, 1 = creative. Higher values produce more varied outputs.', category: 'API' },
    { term: 'Top-P', def: 'Nucleus sampling parameter. The model considers tokens whose cumulative probability exceeds P. Lower = more focused.', category: 'API' },
    { term: 'Batch Inference', def: 'Processing multiple requests together for cost savings (typically 50% discount) with relaxed latency requirements.', category: 'API' },
    { term: 'MoE', def: 'Mixture of Experts. Architecture where only a subset of model parameters are active for each token, improving efficiency.', category: 'Architecture' },
];

const categories = ['All', ...Array.from(new Set(TERMS.map(t => t.category)))];

export default function GlossaryPage({ onNavigate }: Props) {
    const [search, setSearch] = useState('');
    const [cat, setCat] = useState('All');
    const filtered = TERMS.filter(t => (cat === 'All' || t.category === cat) && (t.term.toLowerCase().includes(search.toLowerCase()) || t.def.toLowerCase().includes(search.toLowerCase())));

    return (
        <div style={{ maxWidth: '700px', margin: '0 auto' }}>
            <button className="link-btn" onClick={() => onNavigate('docs')}>‚Üê Docs</button>
            <h1 style={{ margin: '1rem 0' }}>üìñ Glossary</h1>

            <div style={{ display: 'flex', gap: '0.5rem', marginBottom: '1rem', flexWrap: 'wrap' }}>
                <input value={search} onChange={e => setSearch(e.target.value)} placeholder="Search terms..." style={{ flex: 1, minWidth: '150px', padding: '0.4rem 0.6rem', borderRadius: '6px', background: 'rgba(0,0,0,0.3)', border: '1px solid rgba(255,255,255,0.08)', color: '#fff', fontSize: '0.8rem' }} />
                {categories.map(c => (
                    <button key={c} onClick={() => setCat(c)} style={{ padding: '0.25rem 0.5rem', borderRadius: '8px', border: 'none', cursor: 'pointer', fontSize: '0.65rem', fontWeight: 600, background: cat === c ? 'rgba(0,212,255,0.15)' : 'rgba(255,255,255,0.04)', color: cat === c ? '#00d4ff' : 'rgba(255,255,255,0.3)' }}>{c}</button>
                ))}
            </div>

            {filtered.map(t => (
                <div key={t.term} style={{ padding: '0.5rem 0.75rem', marginBottom: '0.3rem', background: 'rgba(255,255,255,0.02)', border: '1px solid rgba(255,255,255,0.06)', borderRadius: '8px' }}>
                    <div style={{ display: 'flex', gap: '0.4rem', alignItems: 'center', marginBottom: '0.15rem' }}>
                        <span style={{ fontWeight: 700, fontSize: '0.9rem', color: '#00d4ff' }}>{t.term}</span>
                        <span style={{ fontSize: '0.55rem', padding: '0.05rem 0.2rem', borderRadius: '3px', background: 'rgba(255,255,255,0.04)', color: 'rgba(255,255,255,0.2)' }}>{t.category}</span>
                    </div>
                    <div style={{ fontSize: '0.78rem', color: 'rgba(255,255,255,0.4)', lineHeight: 1.5 }}>{t.def}</div>
                </div>
            ))}
            <div style={{ fontSize: '0.6rem', color: 'rgba(255,255,255,0.15)', textAlign: 'center', marginTop: '0.5rem' }}>{filtered.length} terms</div>
        </div>
    );
}
